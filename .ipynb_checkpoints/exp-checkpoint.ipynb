{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(Diters=5, adam=False, batchSize=2, beta1=0.5, clamp_lower=-0.01, clamp_upper=0.01, cuda=False, experiment=None, lrD=5e-05, lrG=5e-05, mlp_D=True, mlp_G=True, nSize=147, n_extra_layers=0, ndf=64, neg_data='imgs/test.csv', netD='', netG='', netP='samples/netD_epoch_24.pth', ngf=64, ngpu=1, niter=25, noBN=False, nz=147, pos_data='imgs/test.csv', workers=2)\n",
      "Random Seed:  8753\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "from dataset import DatasetFromPandas\n",
    "import models.dcgan as dcgan\n",
    "import models.mlp as mlp\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--pos_data', default='imgs/test.csv', help='path to dataset')\n",
    "parser.add_argument('--neg_data', default='imgs/test.csv', help='path to dataset')\n",
    "parser.add_argument('--workers', type=int, help='number of data loading workers', default=2)\n",
    "parser.add_argument('--batchSize', type=int, default=2, help='input batch size')\n",
    "parser.add_argument('--nSize', type=int, default=147, help='noise size')\n",
    "parser.add_argument('--nz', type=int, default=147, help='size of the latent z vector')\n",
    "parser.add_argument('--ngf', type=int, default=64)\n",
    "parser.add_argument('--ndf', type=int, default=64)\n",
    "parser.add_argument('--niter', type=int, default=25, help='number of epochs to train for')\n",
    "parser.add_argument('--lrD', type=float, default=0.00005, help='learning rate for Critic, default=0.00005')\n",
    "parser.add_argument('--lrG', type=float, default=0.00005, help='learning rate for Generator, default=0.00005')\n",
    "parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for adam. default=0.5')\n",
    "parser.add_argument('--cuda'  , action='store_true', help='enables cuda')\n",
    "parser.add_argument('--ngpu'  , type=int, default=1, help='number of GPUs to use')\n",
    "parser.add_argument('--netG', default='', help=\"path to netG (to continue training)\")\n",
    "parser.add_argument('--netD', default='', help=\"path to netD (to continue training)\")\n",
    "parser.add_argument('--netP', default='samples/netD_epoch_24.pth', help=\"path to netP (to continue training)\")\n",
    "parser.add_argument('--clamp_lower', type=float, default=-0.01)\n",
    "parser.add_argument('--clamp_upper', type=float, default=0.01)\n",
    "parser.add_argument('--Diters', type=int, default=5, help='number of D iters per each G iter')\n",
    "parser.add_argument('--noBN', action='store_true', help='use batchnorm or not (only for DCGAN)')\n",
    "parser.add_argument('--mlp_G', action='store_true',default=True, help='use MLP for G')\n",
    "parser.add_argument('--mlp_D', action='store_true', default=True,help='use MLP for D')\n",
    "parser.add_argument('--n_extra_layers', type=int, default=0, help='Number of extra layers on gen and disc')\n",
    "parser.add_argument('--experiment', default=None, help='Where to store samples and models')\n",
    "parser.add_argument('--adam', action='store_true', help='Whether to use adam (default is rmsprop)')\n",
    "opt, unknown = parser.parse_known_args()\n",
    "print(opt)\n",
    "\n",
    "\n",
    "if opt.experiment is None:\n",
    "    opt.experiment = 'samples'\n",
    "os.system('mkdir {0}'.format(opt.experiment))\n",
    "\n",
    "opt.manualSeed = random.randint(1, 10000) # fix seed\n",
    "print(\"Random Seed: \", opt.manualSeed)\n",
    "random.seed(opt.manualSeed)\n",
    "torch.manual_seed(opt.manualSeed)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "if torch.cuda.is_available() and not opt.cuda:\n",
    "    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP_G (\n",
      "  (main): Sequential (\n",
      "    (0): Linear (147 -> 64)\n",
      "    (1): ReLU (inplace)\n",
      "    (2): Linear (64 -> 64)\n",
      "    (3): ReLU (inplace)\n",
      "    (4): Linear (64 -> 64)\n",
      "    (5): ReLU (inplace)\n",
      "    (6): Linear (64 -> 147)\n",
      "  )\n",
      ")\n",
      "MLP_D (\n",
      "  (main): Sequential (\n",
      "    (0): Linear (147 -> 64)\n",
      "    (1): ReLU (inplace)\n",
      "    (2): Linear (64 -> 64)\n",
      "    (3): ReLU (inplace)\n",
      "    (4): Linear (64 -> 64)\n",
      "    (5): ReLU (inplace)\n",
      "    (6): Linear (64 -> 1)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'netP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-153d24fa503a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetP\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# load checkpoint if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mnetP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'netP' is not defined"
     ]
    }
   ],
   "source": [
    "pos_data = DatasetFromPandas(opt.pos_data)\n",
    "\n",
    "neg_data = DatasetFromPandas(opt.neg_data)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(pos_data, batch_size=opt.batchSize,\n",
    "                                         shuffle=True, num_workers=int(opt.workers))\n",
    "neg_dataloader = torch.utils.data.DataLoader(neg_data, batch_size=opt.batchSize,\n",
    "                                         shuffle=True, num_workers=int(opt.workers))\n",
    "\n",
    "ngpu = int(opt.ngpu)\n",
    "nz = int(opt.nz)\n",
    "ngf = int(opt.ngf)\n",
    "ndf = int(opt.ndf)\n",
    "n_extra_layers = int(opt.n_extra_layers)\n",
    "\n",
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "if opt.noBN:\n",
    "    netG = dcgan.DCGAN_G_nobn(opt.imageSize, nz, nc, ngf, ngpu, n_extra_layers)\n",
    "elif opt.mlp_G:\n",
    "    netG = mlp.MLP_G(nz, nz,  ngf, ngpu)\n",
    "else:\n",
    "    netG = dcgan.DCGAN_G(opt.imageSize, nz, nc, ngf, ngpu, n_extra_layers)\n",
    "\n",
    "netG.apply(weights_init)\n",
    "if opt.netG != '': # load checkpoint if needed\n",
    "    netG.load_state_dict(torch.load(opt.netG))\n",
    "print(netG)\n",
    "\n",
    "if opt.mlp_D:\n",
    "    netD = mlp.MLP_D(opt.nSize,  ndf, ngpu)\n",
    "else:\n",
    "    netD = dcgan.DCGAN_D(opt.imageSize, nz, nc, ndf, ngpu, n_extra_layers)\n",
    "    netD.apply(weights_init)\n",
    "\n",
    "if opt.netD != '':\n",
    "    netD.load_state_dict(torch.load(opt.netD))\n",
    "print(netD)\n",
    "\n",
    "# if opt.netP != '': # load checkpoint if needed\n",
    "#     netP.load_state_dict(torch.load(opt.netG))\n",
    "\n",
    "input = torch.FloatTensor(opt.batchSize, opt.nSize)\n",
    "noise = torch.FloatTensor(opt.batchSize, nz, 1, 1)\n",
    "# fixed_noise = torch.FloatTensor(opt.batchSize, nz, 1, 1).normal_(0, 1)\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1\n",
    "\n",
    "if opt.cuda:\n",
    "    netD.cuda()\n",
    "    netG.cuda()\n",
    "    input = input.cuda()\n",
    "    one, mone = one.cuda(), mone.cuda()\n",
    "    noise, fixed_noise = noise.cuda(), fixed_noise.cuda()\n",
    "\n",
    "# setup optimizer\n",
    "if opt.adam:\n",
    "    optimizerD = optim.Adam(netD.parameters(), lr=opt.lrD, betas=(opt.beta1, 0.999))\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=opt.lrG, betas=(opt.beta1, 0.999))\n",
    "else:\n",
    "    optimizerD = optim.RMSprop(netD.parameters(), lr = opt.lrD)\n",
    "    optimizerG = optim.RMSprop(netG.parameters(), lr = opt.lrG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([1, 147])\n",
      "[0/25][5/5][1] Loss_D: -0.000018 Loss_G: -0.011004 Loss_D_real: -0.011018 Loss_D_fake -0.010999\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([1, 147])\n",
      "[1/25][5/5][2] Loss_D: -0.000053 Loss_G: -0.010980 Loss_D_real: -0.011018 Loss_D_fake -0.010965\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([1, 147])\n",
      "[2/25][5/5][3] Loss_D: -0.000096 Loss_G: -0.010953 Loss_D_real: -0.011037 Loss_D_fake -0.010941\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([1, 147])\n",
      "[3/25][5/5][4] Loss_D: -0.000130 Loss_G: -0.010926 Loss_D_real: -0.011049 Loss_D_fake -0.010919\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([1, 147])\n",
      "[4/25][5/5][5] Loss_D: -0.000212 Loss_G: -0.010901 Loss_D_real: -0.011107 Loss_D_fake -0.010895\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([1, 147])\n",
      "[5/25][5/5][6] Loss_D: -0.000263 Loss_G: -0.010869 Loss_D_real: -0.011132 Loss_D_fake -0.010869\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([1, 147])\n",
      "[6/25][5/5][7] Loss_D: -0.000382 Loss_G: -0.010831 Loss_D_real: -0.011214 Loss_D_fake -0.010832\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([1, 147])\n",
      "[7/25][5/5][8] Loss_D: -0.000457 Loss_G: -0.010789 Loss_D_real: -0.011251 Loss_D_fake -0.010794\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([1, 147])\n",
      "[8/25][5/5][9] Loss_D: -0.000583 Loss_G: -0.010742 Loss_D_real: -0.011338 Loss_D_fake -0.010755\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([1, 147])\n",
      "[9/25][5/5][10] Loss_D: -0.000602 Loss_G: -0.010692 Loss_D_real: -0.011305 Loss_D_fake -0.010703\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([1, 147])\n",
      "[10/25][5/5][11] Loss_D: -0.000807 Loss_G: -0.010643 Loss_D_real: -0.011459 Loss_D_fake -0.010652\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([1, 147])\n",
      "[11/25][5/5][12] Loss_D: -0.000874 Loss_G: -0.010598 Loss_D_real: -0.011484 Loss_D_fake -0.010610\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([1, 147])\n",
      "[12/25][5/5][13] Loss_D: -0.001015 Loss_G: -0.010555 Loss_D_real: -0.011586 Loss_D_fake -0.010570\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([1, 147])\n",
      "[13/25][5/5][14] Loss_D: -0.001117 Loss_G: -0.010513 Loss_D_real: -0.011647 Loss_D_fake -0.010530\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([1, 147])\n",
      "[14/25][5/5][15] Loss_D: -0.001184 Loss_G: -0.010470 Loss_D_real: -0.011672 Loss_D_fake -0.010488\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([1, 147])\n",
      "[15/25][5/5][16] Loss_D: -0.001343 Loss_G: -0.010431 Loss_D_real: -0.011793 Loss_D_fake -0.010450\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([1, 147])\n",
      "[16/25][5/5][17] Loss_D: -0.001358 Loss_G: -0.010395 Loss_D_real: -0.011774 Loss_D_fake -0.010415\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([1, 147])\n",
      "[17/25][5/5][18] Loss_D: -0.001494 Loss_G: -0.010366 Loss_D_real: -0.011870 Loss_D_fake -0.010376\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([1, 147])\n",
      "[18/25][5/5][19] Loss_D: -0.001824 Loss_G: -0.010333 Loss_D_real: -0.012174 Loss_D_fake -0.010350\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([1, 147])\n",
      "[19/25][5/5][20] Loss_D: -0.001924 Loss_G: -0.010298 Loss_D_real: -0.012239 Loss_D_fake -0.010316\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([1, 147])\n",
      "[20/25][5/5][21] Loss_D: -0.002097 Loss_G: -0.010266 Loss_D_real: -0.012378 Loss_D_fake -0.010281\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([1, 147])\n",
      "[21/25][5/5][22] Loss_D: -0.002130 Loss_G: -0.010237 Loss_D_real: -0.012380 Loss_D_fake -0.010249\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([1, 147])\n",
      "[22/25][5/5][23] Loss_D: -0.002385 Loss_G: -0.010210 Loss_D_real: -0.012608 Loss_D_fake -0.010223\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([1, 147])\n",
      "[23/25][5/5][24] Loss_D: -0.002618 Loss_G: -0.010175 Loss_D_real: -0.012809 Loss_D_fake -0.010191\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([2, 147])\n",
      "input torch.Size([1, 147])\n",
      "[24/25][5/5][25] Loss_D: -0.002695 Loss_G: -0.010149 Loss_D_real: -0.012868 Loss_D_fake -0.010174\n"
     ]
    }
   ],
   "source": [
    "gen_iterations = 0\n",
    "for epoch in range(opt.niter):\n",
    "    data_iter = iter(dataloader)\n",
    "    neg_iter = iter(neg_dataloader)\n",
    "\n",
    "    i = 0\n",
    "    while i < len(dataloader):\n",
    "        ############################\n",
    "        # (1) Update D network\n",
    "        ###########################\n",
    "        for p in netD.parameters(): # reset requires_grad\n",
    "            p.requires_grad = True # they are set to False below in netG update\n",
    "\n",
    "        # train the discriminator Diters times\n",
    "        if gen_iterations < 25 or gen_iterations % 500 == 0:\n",
    "            Diters = 100\n",
    "        else:\n",
    "            Diters = opt.Diters\n",
    "        j = 0\n",
    "        while j < Diters and i < len(dataloader):\n",
    "            j += 1\n",
    "            # clamp parameters to a cube\n",
    "            for p in netD.parameters():\n",
    "                p.data.clamp_(opt.clamp_lower, opt.clamp_upper)\n",
    "\n",
    "            data = data_iter.next()\n",
    "            i += 1\n",
    "\n",
    "            # train with real\n",
    "            real_cpu = data\n",
    "            netD.zero_grad()\n",
    "            # batch_size = real_cpu.size(0)\n",
    "\n",
    "            if opt.cuda:\n",
    "                real_cpu = real_cpu.cuda()\n",
    "            input.resize_as_(real_cpu).copy_(real_cpu)\n",
    "            inputv = Variable(input)\n",
    "\n",
    "            errD_real = netD(inputv)\n",
    "            errD_real.backward(one)\n",
    "\n",
    "            # train with fake\n",
    "            try:\n",
    "                noise = neg_iter.next()\n",
    "#                 print (noise.size())\n",
    "            except:\n",
    "                neg_iter = iter(neg_dataloader)\n",
    "                noise = neg_iter.next()\n",
    "\n",
    "            # noise.resize_(opt.batchSize, nz, 1, 1).normal_(0, 1)\n",
    "            noisev = Variable(noise, volatile = True) # totally freeze netG\n",
    "            fake = Variable(netG(noisev).data)\n",
    "            inputv = fake\n",
    "            errD_fake = netD(inputv)\n",
    "            errD_fake.backward(mone)\n",
    "            errD = errD_real - errD_fake\n",
    "            optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network\n",
    "        ###########################\n",
    "        for p in netD.parameters():\n",
    "            p.requires_grad = False # to avoid computation\n",
    "        netG.zero_grad()\n",
    "        # in case our last batch was the tail batch of the dataloader,\n",
    "        # make sure we feed a full batch of noise\n",
    "        # noise.resize_(opt.batchSize, nz, 1, 1).normal_(0, 1)\n",
    "        try:\n",
    "                noise = neg_iter.next()\n",
    "                \n",
    "        except:\n",
    "                neg_iter = iter(neg_dataloader)\n",
    "                noise = neg_iter.next()\n",
    "\n",
    "        noisev = Variable(noise)\n",
    "        fake = netG(noisev)\n",
    "        errG = netD(fake)\n",
    "\n",
    "        errG.backward(one)\n",
    "        optimizerG.step()\n",
    "        gen_iterations += 1\n",
    "\n",
    "        print('[%d/%d][%d/%d][%d] Loss_D: %f Loss_G: %f Loss_D_real: %f Loss_D_fake %f'\n",
    "            % (epoch, opt.niter, i, len(dataloader), gen_iterations,\n",
    "            errD.data[0], errG.data[0], errD_real.data[0], errD_fake.data[0]))\n",
    "        #print ('err',errD.size(), errG.size(), errD_real.size(), errD_fake.size(),)\n",
    "\n",
    "        if gen_iterations % 500 == 0:\n",
    "            # real_cpu = real_cpu.mul(0.5).add(0.5)\n",
    "            # fake = netG(Variable(fixed_noise, volatile=True))\n",
    "            # fake.data = fake.data.mul(0.5).add(0.5)\n",
    "            pass\n",
    "torch.save(netD.state_dict(), '{0}/netD_epoch_{1}.pth'.format(opt.experiment, epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dataset import DatasetFromPandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = DatasetFromPandas('imgs/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(test, batch_size=opt.batchSize,\n",
    "                                         shuffle=True, num_workers=int(opt.workers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataiter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "real_cpu = dataiter.next()\n",
    "inputv = Variable(real_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test1 = iter(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([147])\n",
      "torch.Size([147])\n",
      "torch.Size([147])\n",
      "torch.Size([147])\n",
      "torch.Size([147])\n",
      "torch.Size([147])\n",
      "torch.Size([147])\n",
      "torch.Size([147])\n",
      "torch.Size([147])\n",
      "torch.Size([147])\n",
      "torch.Size([147])\n",
      "torch.Size([147])\n",
      "torch.Size([147])\n",
      "torch.Size([147])\n",
      "torch.Size([147])\n",
      "torch.Size([147])\n",
      "torch.Size([147])\n",
      "torch.Size([147])\n",
      "torch.Size([147])\n",
      "torch.Size([147])\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    \n",
    "    try:\n",
    "#         print (i,'pos')\n",
    "        print (test1.next().size())\n",
    "    except:\n",
    "#         print (i,'neg')\n",
    "        test = DatasetFromPandas('imgs/test.csv')\n",
    "        test1 = iter(test)\n",
    "        print (test1.next().size())\n",
    "\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "netP = mlp.MLP_P(opt.nSize,  ndf, ngpu)\n",
    "\n",
    "netP.load_state_dict(torch.load(opt.netP))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01307047],\n",
       "       [-0.01302315]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netP(inputv).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
