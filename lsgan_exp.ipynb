{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(Diters=5, adam=False, batchSize=128, beta1=0.5, clamp_lower=-0.01, clamp_upper=0.01, cuda=True, experiment=None, lrD=5e-05, lrG=5e-05, mlp_D=True, mlp_G=True, nSize=148, n_extra_layers=0, ndf=64, neg_data='/storage03/user_data/liuchen01/creds/train_pos.dat', netD='', netG='', netP='samples/netD_epoch_24.pth', ngf=64, ngpu=1, niter=25, noBN=False, nz=148, pos_data='/storage03/user_data/liuchen01/creds/train_neg.dat', test_data='/storage03/user_data/liuchen01/creds/test_feature.dat', test_label='/storage03/user_data/liuchen01/creds/test_labels.dat', workers=2)\n",
      "Random Seed:  1224\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "from dataset import DatasetFromPandas\n",
    "import models.dcgan as dcgan\n",
    "import models.mlp as mlp\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--pos_data', default='/storage03/user_data/liuchen01/creds/train_neg.dat', help='path to dataset')\n",
    "parser.add_argument('--neg_data', default='/storage03/user_data/liuchen01/creds/train_pos.dat', help='path to dataset')\n",
    "parser.add_argument('--test_data', default='/storage03/user_data/liuchen01/creds/test_feature.dat', help='path to dataset')\n",
    "parser.add_argument('--test_label', default='/storage03/user_data/liuchen01/creds/test_labels.dat', help='path to dataset')\n",
    "parser.add_argument('--workers', type=int, help='number of data loading workers', default=2)\n",
    "parser.add_argument('--batchSize', type=int, default=128, help='input batch size')\n",
    "parser.add_argument('--nSize', type=int, default=148, help='noise size')\n",
    "parser.add_argument('--nz', type=int, default=148, help='size of the latent z vector')\n",
    "parser.add_argument('--ngf', type=int, default=64)\n",
    "parser.add_argument('--ndf', type=int, default=64)\n",
    "parser.add_argument('--niter', type=int, default=25, help='number of epochs to train for')\n",
    "parser.add_argument('--lrD', type=float, default=0.00005, help='learning rate for Critic, default=0.00005')\n",
    "parser.add_argument('--lrG', type=float, default=0.00005, help='learning rate for Generator, default=0.00005')\n",
    "parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for adam. default=0.5')\n",
    "parser.add_argument('--cuda'  , action='store_true',default=True, help='enables cuda')\n",
    "parser.add_argument('--ngpu'  , type=int, default=1, help='number of GPUs to use')\n",
    "parser.add_argument('--netG', default='', help=\"path to netG (to continue training)\")\n",
    "parser.add_argument('--netD', default='', help=\"path to netD (to continue training)\")\n",
    "parser.add_argument('--netP', default='samples/netD_epoch_24.pth', help=\"path to netP (to continue training)\")\n",
    "parser.add_argument('--clamp_lower', type=float, default=-0.01)\n",
    "parser.add_argument('--clamp_upper', type=float, default=0.01)\n",
    "parser.add_argument('--Diters', type=int, default=5, help='number of D iters per each G iter')\n",
    "parser.add_argument('--noBN', action='store_true', help='use batchnorm or not (only for DCGAN)')\n",
    "parser.add_argument('--mlp_G', action='store_true',default=True, help='use MLP for G')\n",
    "parser.add_argument('--mlp_D', action='store_true', default=True,help='use MLP for D')\n",
    "parser.add_argument('--n_extra_layers', type=int, default=0, help='Number of extra layers on gen and disc')\n",
    "parser.add_argument('--experiment', default=None, help='Where to store samples and models')\n",
    "parser.add_argument('--adam', action='store_true', help='Whether to use adam (default is rmsprop)')\n",
    "opt, unknown = parser.parse_known_args()\n",
    "print(opt)\n",
    "\n",
    "\n",
    "if opt.experiment is None:\n",
    "    opt.experiment = 'samples'\n",
    "os.system('mkdir {0}'.format(opt.experiment))\n",
    "\n",
    "opt.manualSeed = random.randint(1, 10000) # fix seed\n",
    "print(\"Random Seed: \", opt.manualSeed)\n",
    "random.seed(opt.manualSeed)\n",
    "torch.manual_seed(opt.manualSeed)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "if torch.cuda.is_available() and not opt.cuda:\n",
    "    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_data = DatasetFromPandas(opt.pos_data)\n",
    "\n",
    "neg_data = DatasetFromPandas(opt.neg_data)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(pos_data, batch_size=opt.batchSize,\n",
    "                                         shuffle=True, num_workers=int(opt.workers))\n",
    "neg_dataloader = torch.utils.data.DataLoader(neg_data, batch_size=opt.batchSize,\n",
    "                                         shuffle=True, num_workers=int(opt.workers))\n",
    "test = DatasetFromPandas(opt.test_data)\n",
    "labels = list(pd.read_csv(opt.test_label,header=None)[0])\n",
    "testdataloader = torch.utils.data.DataLoader(test, batch_size=len(test),\n",
    "                                         shuffle=False, num_workers=int(opt.workers))\n",
    "testdataiter = iter(testdataloader)\n",
    "testv = Variable(testdataiter.next()).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traindataloader = torch.utils.data.DataLoader(pos_data, batch_size=len(pos_data),\n",
    "                                         shuffle=True, num_workers=int(opt.workers))\n",
    "traindataiter = iter(traindataloader)\n",
    "\n",
    "trainv = Variable(traindataiter.next()).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential (\n",
      "  (0): Linear (148 -> 64)\n",
      "  (1): Dropout (p = 0.3)\n",
      "  (2): ReLU ()\n",
      "  (3): Linear (64 -> 64)\n",
      "  (4): Dropout (p = 0.3)\n",
      "  (5): ReLU ()\n",
      "  (6): Linear (64 -> 148)\n",
      "  (7): Sigmoid ()\n",
      ")\n",
      "Sequential (\n",
      "  (0): Linear (148 -> 64)\n",
      "  (1): Dropout (p = 0.3)\n",
      "  (2): ReLU (inplace)\n",
      "  (3): Linear (64 -> 64)\n",
      "  (4): Dropout (p = 0.3)\n",
      "  (5): ReLU (inplace)\n",
      "  (6): Linear (64 -> 1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ngpu = int(opt.ngpu)\n",
    "nSize = int(opt.nz)\n",
    "\n",
    "nz = int(opt.nz)\n",
    "nSize = int (opt.nSize)\n",
    "ngf = int(opt.ngf)\n",
    "ndf = int(opt.ndf)\n",
    "n_extra_layers = int(opt.n_extra_layers)\n",
    "netG = nn.Sequential(\n",
    "    # Z goes into a linear of size: ngf\n",
    "    nn.Linear(nz, ngf),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(ngf, ngf),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.ReLU(),\n",
    "#     nn.Linear(ngf, ngf),\n",
    "#     nn.Dropout(0.3)\n",
    "#     nn.ReLU(True),\n",
    "    nn.Linear(ngf, nSize),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "netD = nn.Sequential(\n",
    "    nn.Linear(nSize, ndf),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.ReLU(True),\n",
    "    nn.Linear(ndf, ndf),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.ReLU(True),\n",
    "#     nn.Linear(ndf, ndf),\n",
    "#     nn.ReLU(True),\n",
    "    nn.Linear(ndf, 1),\n",
    "#     nn.Softmax()\n",
    ")\n",
    "print (netG)\n",
    "print (netD)\n",
    "input = torch.FloatTensor(opt.batchSize, opt.nSize)\n",
    "noise = torch.FloatTensor(opt.batchSize, nz)\n",
    "# fixed_noise = torch.FloatTensor(opt.batchSize, nz, 1, 1).normal_(0, 1)\n",
    "if opt.cuda:\n",
    "    netD.cuda()\n",
    "    netG.cuda()\n",
    "    input = input.cuda()\n",
    "    noise = noise.cuda()\n",
    "\n",
    "# setup optimizer\n",
    "if opt.adam:\n",
    "    optimizerD = optim.Adam(netD.parameters(), lr=opt.lrD, betas=(opt.beta1, 0.999))\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=opt.lrG, betas=(opt.beta1, 0.999))\n",
    "else:\n",
    "    optimizerD = optim.RMSprop(netD.parameters(), lr = opt.lrD)\n",
    "    optimizerG = optim.RMSprop(netG.parameters(), lr = opt.lrG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = torch.FloatTensor(opt.batchSize, opt.nSize)\n",
    "\n",
    "\n",
    "if opt.cuda:\n",
    "    netD.cuda()\n",
    "    netG.cuda()\n",
    "    input = input.cuda()\n",
    "    # noise, fixed_noise = noise.cuda(), fixed_noise.cuda()\n",
    "\n",
    "# setup optimizer\n",
    "if opt.adam:\n",
    "    optimizerD = optim.Adam(netD.parameters(), lr=opt.lrD, betas=(opt.beta1, 0.999))\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=opt.lrG, betas=(opt.beta1, 0.999))\n",
    "else:\n",
    "    optimizerD = optim.RMSprop(netD.parameters(), lr = opt.lrD)\n",
    "    optimizerG = optim.RMSprop(netG.parameters(), lr = opt.lrG)\n",
    "test = DatasetFromPandas(opt.test_data)\n",
    "labels = list(pd.read_csv(opt.test_label,header=None)[0])\n",
    "def reset_grad():\n",
    "    netG.zero_grad()\n",
    "    netD.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.9350\n",
      " 0.8219\n",
      " 0.9100\n",
      " 0.9322\n",
      " 0.9694\n",
      " 0.8248\n",
      " 0.8943\n",
      " 0.7847\n",
      " 0.7091\n",
      " 1.0516\n",
      "[torch.cuda.FloatTensor of size 10x1 (GPU 0)]\n",
      " Variable containing:\n",
      "1.00000e-02 *\n",
      " -0.3154\n",
      "  1.0954\n",
      "  1.0354\n",
      "  3.8210\n",
      "  3.6852\n",
      "  0.5093\n",
      "  1.3435\n",
      "  0.2414\n",
      "  1.3880\n",
      " -2.5157\n",
      "[torch.cuda.FloatTensor of size 10x1 (GPU 0)]\n",
      "\n",
      "[0/25][1662/1662] Loss_D: 0.015447 Loss_G: 0.497408 \n",
      "Variable containing:\n",
      " 0.8328\n",
      " 1.0118\n",
      " 0.8787\n",
      " 1.1296\n",
      " 0.8383\n",
      " 0.9026\n",
      " 0.9553\n",
      " 0.8542\n",
      " 1.0634\n",
      " 1.0885\n",
      "[torch.cuda.FloatTensor of size 10x1 (GPU 0)]\n",
      " Variable containing:\n",
      "1.00000e-02 *\n",
      " -1.0305\n",
      " -3.3722\n",
      "  0.0367\n",
      "  1.5655\n",
      "  2.7129\n",
      "  2.2456\n",
      "  1.2637\n",
      "  0.8703\n",
      "  1.2387\n",
      " -1.1638\n",
      "[torch.cuda.FloatTensor of size 10x1 (GPU 0)]\n",
      "\n",
      "[1/25][1662/1662] Loss_D: 0.010157 Loss_G: 0.490268 \n",
      "Variable containing:\n",
      " 1.1486\n",
      " 1.1159\n",
      " 1.1619\n",
      " 0.9182\n",
      " 1.0819\n",
      " 0.7002\n",
      " 0.7507\n",
      " 1.1327\n",
      " 0.7615\n",
      " 1.1194\n",
      "[torch.cuda.FloatTensor of size 10x1 (GPU 0)]\n",
      " Variable containing:\n",
      " 0.0904\n",
      " 0.1213\n",
      "-0.0261\n",
      " 0.1201\n",
      " 0.0035\n",
      "-0.0036\n",
      "-0.0138\n",
      " 0.3166\n",
      "-0.0772\n",
      " 0.1057\n",
      "[torch.cuda.FloatTensor of size 10x1 (GPU 0)]\n",
      "\n",
      "[2/25][1662/1662] Loss_D: 0.017468 Loss_G: 0.456527 \n",
      "Variable containing:\n",
      " 1.0319\n",
      " 1.1420\n",
      " 0.8551\n",
      " 0.8435\n",
      " 1.0211\n",
      " 0.9283\n",
      " 1.2557\n",
      " 1.0014\n",
      " 0.7014\n",
      " 0.9470\n",
      "[torch.cuda.FloatTensor of size 10x1 (GPU 0)]\n",
      " Variable containing:\n",
      "-0.0410\n",
      " 0.0157\n",
      " 0.2172\n",
      " 0.2458\n",
      "-0.0301\n",
      " 0.1101\n",
      " 0.2987\n",
      " 0.3449\n",
      " 0.1041\n",
      " 0.3266\n",
      "[torch.cuda.FloatTensor of size 10x1 (GPU 0)]\n",
      "\n",
      "[3/25][1662/1662] Loss_D: 0.029758 Loss_G: 0.460685 \n",
      "Variable containing:\n",
      " 0.9411\n",
      " 0.9702\n",
      " 0.8189\n",
      " 0.8330\n",
      " 0.7834\n",
      " 1.0634\n",
      " 0.9155\n",
      " 0.9751\n",
      " 1.0697\n",
      " 1.0312\n",
      "[torch.cuda.FloatTensor of size 10x1 (GPU 0)]\n",
      " Variable containing:\n",
      " 0.2451\n",
      "-0.0300\n",
      " 0.1708\n",
      " 0.0640\n",
      " 0.0991\n",
      "-0.0327\n",
      " 0.0868\n",
      " 0.1179\n",
      " 0.1088\n",
      " 0.0650\n",
      "[torch.cuda.FloatTensor of size 10x1 (GPU 0)]\n",
      "\n",
      "[4/25][1662/1662] Loss_D: 0.043607 Loss_G: 0.438326 \n",
      "Variable containing:\n",
      " 0.9799\n",
      " 0.9790\n",
      " 1.0198\n",
      " 0.8559\n",
      " 1.0212\n",
      " 1.0010\n",
      " 0.8911\n",
      " 0.8930\n",
      " 1.0392\n",
      " 1.1399\n",
      "[torch.cuda.FloatTensor of size 10x1 (GPU 0)]\n",
      " Variable containing:\n",
      "-0.0559\n",
      " 0.1151\n",
      " 0.1943\n",
      " 0.0234\n",
      " 0.0861\n",
      " 0.4083\n",
      "-0.1300\n",
      " 0.0924\n",
      " 0.1886\n",
      " 0.0593\n",
      "[torch.cuda.FloatTensor of size 10x1 (GPU 0)]\n",
      "\n",
      "[5/25][1662/1662] Loss_D: 0.017666 Loss_G: 0.457435 \n",
      "Variable containing:\n",
      " 0.9194\n",
      " 1.0081\n",
      " 1.0241\n",
      " 0.9707\n",
      " 1.0213\n",
      " 0.9916\n",
      " 1.0299\n",
      " 0.7531\n",
      " 0.9529\n",
      " 1.0472\n",
      "[torch.cuda.FloatTensor of size 10x1 (GPU 0)]\n",
      " Variable containing:\n",
      " 0.1217\n",
      " 0.0144\n",
      "-0.0064\n",
      " 0.1003\n",
      " 0.0435\n",
      " 0.1593\n",
      "-0.1191\n",
      " 0.0568\n",
      " 0.0663\n",
      "-0.0099\n",
      "[torch.cuda.FloatTensor of size 10x1 (GPU 0)]\n",
      "\n",
      "[6/25][1662/1662] Loss_D: 0.024836 Loss_G: 0.493090 \n",
      "Variable containing:\n",
      " 1.0184\n",
      " 0.8803\n",
      " 0.9272\n",
      " 0.8616\n",
      " 0.9955\n",
      " 0.7926\n",
      " 0.8955\n",
      " 1.0826\n",
      " 0.9350\n",
      " 1.0831\n",
      "[torch.cuda.FloatTensor of size 10x1 (GPU 0)]\n",
      " Variable containing:\n",
      " 0.1879\n",
      " 0.1698\n",
      "-0.3482\n",
      " 0.0591\n",
      "-0.0570\n",
      "-0.0022\n",
      "-0.1771\n",
      "-0.2177\n",
      " 0.2422\n",
      "-0.0229\n",
      "[torch.cuda.FloatTensor of size 10x1 (GPU 0)]\n",
      "\n",
      "[7/25][1662/1662] Loss_D: 0.035899 Loss_G: 0.488888 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-90:\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Process Process-88:\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Process Process-87:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-b250587a1b94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0merrD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_real\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_fake\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0merrD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[0moptimizerD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m             \u001b[0mreset_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/torch/optim/rmsprop.pyc\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m                     \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m                 \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 41, in _worker_loop\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"dataset.py\", line 11, in __getitem__\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 35, in _worker_loop\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 41, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "    return torch.from_numpy(np.array(self.data.iloc[index])).float()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "  File \"dataset.py\", line 11, in __getitem__\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/pandas/core/indexing.py\", line 1328, in __getitem__\n",
      "    return recv()\n",
      "    return torch.from_numpy(np.array(self.data.iloc[index])).float()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/multiprocessing/queue.py\", line 21, in recv\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/pandas/core/indexing.py\", line 1328, in __getitem__\n",
      "    return self._getitem_axis(key, axis=0)\n",
      "    buf = self.recv_bytes()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/pandas/core/indexing.py\", line 1751, in _getitem_axis\n",
      "    return self._getitem_axis(key, axis=0)\n",
      "    return self._get_loc(key, axis=axis)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/pandas/core/indexing.py\", line 1751, in _getitem_axis\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/pandas/core/indexing.py\", line 139, in _get_loc\n",
      "    return self._get_loc(key, axis=axis)\n",
      "    return self.obj._ixs(key, axis=axis)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/pandas/core/indexing.py\", line 139, in _get_loc\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/pandas/core/frame.py\", line 1997, in _ixs\n",
      "    return self.obj._ixs(key, axis=axis)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/pandas/core/frame.py\", line 1997, in _ixs\n",
      "    dtype=new_values.dtype)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/pandas/core/series.py\", line 248, in __init__\n",
      "    dtype=new_values.dtype)\n",
      "    raise_cast_failure=True)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/pandas/core/series.py\", line 254, in __init__\n",
      "    self.name = name\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/pandas/core/series.py\", line 3033, in _sanitize_array\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/pandas/core/generic.py\", line 2992, in __setattr__\n",
      "    if issubclass(subarr.dtype.type, compat.string_types):\n",
      "KeyboardInterrupt\n",
      "    object.__setattr__(self, name, value)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/pandas/core/series.py\", line 328, in name\n",
      "    object.__setattr__(self, '_name', value)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    data_iter = iter(dataloader)\n",
    "    neg_iter = iter(neg_dataloader)\n",
    "    d_step = 5\n",
    "    i = 0\n",
    "    while i< len(dataloader):\n",
    "        j = 0\n",
    "        while j<d_step and i < len(dataloader):\n",
    "            ############################\n",
    "            # (1) Update D network\n",
    "            ###########################\n",
    "            j += 1\n",
    "            i += 1\n",
    "            data = data_iter.next()\n",
    "\n",
    "            # sample data with real and fake\n",
    "            real_cpu = data\n",
    "\n",
    "            if opt.cuda:\n",
    "                real_cpu = real_cpu.cuda()\n",
    "            input.resize_as_(real_cpu).copy_(real_cpu)\n",
    "            inputv = Variable(input)\n",
    "            try:\n",
    "                noise = neg_iter.next()\n",
    "    #                 print (noise.size())\n",
    "            except:\n",
    "                neg_iter = iter(neg_dataloader)\n",
    "                noise = neg_iter.next()\n",
    "            if opt.cuda:\n",
    "                noise = noise.cuda()\n",
    "            # noise.resize_(opt.batchSize, nz, 1, 1).normal_(0, 1)\n",
    "            noisev = Variable(noise, volatile = True) # totally freeze netG\n",
    "            fake = Variable(netG(noisev).data)\n",
    "\n",
    "            # Discriminator\n",
    "            D_real = netD(inputv)\n",
    "            D_fake = netD(fake)\n",
    "            errD = 0.5 * (torch.mean((D_real - 1)**2) + torch.mean(D_fake**2))\n",
    "            errD.backward()\n",
    "            optimizerD.step()\n",
    "            reset_grad()\n",
    "\n",
    "            ############################\n",
    "            # (2) Update G network\n",
    "            ###########################\n",
    "        try:\n",
    "                noise = neg_iter.next()\n",
    "\n",
    "        except:\n",
    "                neg_iter = iter(neg_dataloader)\n",
    "                noise = neg_iter.next()\n",
    "        if opt.cuda:\n",
    "            noise = noise.cuda()\n",
    "        noisev = Variable(noise)\n",
    "        fake = netG(noisev)\n",
    "        G_fake = netD(fake)\n",
    "        errG = 0.5 * torch.mean((G_fake - 1)**2)\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "        reset_grad()\n",
    "    print (D_real.cpu().data[:10],D_fake.cpu().data[:10])\n",
    "\n",
    "    print('[%d/%d][%d/%d] Loss_D: %f Loss_G: %f '\n",
    "            % (epoch, opt.niter, i, len(dataloader),\n",
    "            errD.data[0], errG.data[0]))\n",
    "#         pred_probs = (D_real.cpu().data.numpy())\n",
    "#         print (max(pred_probs),min(pred_probs))\n",
    "#         pred_probs = (G_fake.cpu().data.numpy())\n",
    "#         print (max(pred_probs),min(pred_probs))\n",
    "\n",
    "#         pred_probs = (netD(testv).cpu().data.numpy())\n",
    "#         print (max(pred_probs),min(pred_probs),len(pred_probs))\n",
    "#         pred_probs = (netD(netG(testv)).cpu().data.numpy())\n",
    "#         print (max(pred_probs),min(pred_probs),len(pred_probs))\n",
    "    if epoch%5==0:\n",
    "        torch.save(netD.state_dict(), '{0}/lsgan_netD_epoch_{1}.pth'.format(opt.experiment, epoch))\n",
    "#         pred_probs = (netD(testv.cuda()).cpu().data.numpy())\n",
    "#         pred_probs = (pred_probs-min(pred_probs))/(max(pred_probs)-min(pred_probs))\n",
    "#         for i in range(0,10,2):\n",
    "#             pred = [1 if j>i/10.0 else 0 for j in pred_probs ]\n",
    "#             print (confusion_matrix(labels,pred))\n",
    "#             print (\"Accuracy, \",  metrics.accuracy_score(labels,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.89009535],\n",
       "       [ 1.0625751 ],\n",
       "       [ 1.13957906],\n",
       "       [ 0.96736288],\n",
       "       [ 0.86975586],\n",
       "       [ 0.90423822],\n",
       "       [ 0.88350105],\n",
       "       [ 1.06635475],\n",
       "       [ 1.05911839],\n",
       "       [ 0.93840349]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_real.cpu().data[:10].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17108215],\n",
       "       [-0.04602516],\n",
       "       [-0.24130186],\n",
       "       [ 0.12629423],\n",
       "       [ 0.03500208],\n",
       "       [ 0.00803518],\n",
       "       [ 0.08853036],\n",
       "       [ 0.13303322],\n",
       "       [-0.24929819],\n",
       "       [-0.20617774]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_fake.cpu().data[:10].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_probs = (netD((testv)).cpu().data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_pred_probs = (netD((trainv)).cpu().data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175326.33"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.sum(pred_probs[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.55457652], dtype=float32), array([-0.46520892], dtype=float32))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(pred_probs),min(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_probs=[p[1] for p  in pred_probs ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred=[1 if p[0]>p[1] else 0 for p in pred_probs ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     0  53158]\n",
      " [     0 152450]]\n",
      "Accuracy,  0.741459476285\n"
     ]
    }
   ],
   "source": [
    "# pred_probs = (pred_probs-min(pred_probs))/(max(pred_probs)-min(pred_probs))\n",
    "print (confusion_matrix(labels,pred))\n",
    "print (\"Accuracy, \",  metrics.accuracy_score(labels,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 53158      0]\n",
      " [152450      0]]\n",
      "Accuracy,  0.258540523715\n",
      "[[  4617  48541]\n",
      " [ 18695 133755]]\n",
      "Accuracy,  0.672989377845\n",
      "[[  4512  48646]\n",
      " [ 18117 134333]]\n",
      "Accuracy,  0.675289871989\n",
      "[[  4460  48698]\n",
      " [ 17740 134710]]\n",
      "Accuracy,  0.676870549784\n",
      "[[  4410  48748]\n",
      " [ 17439 135011]]\n",
      "Accuracy,  0.678091319404\n",
      "[[  4354  48804]\n",
      " [ 17160 135290]]\n",
      "Accuracy,  0.679175907552\n",
      "[[  4310  48848]\n",
      " [ 16894 135556]]\n",
      "Accuracy,  0.680255632077\n",
      "[[  4259  48899]\n",
      " [ 16610 135840]]\n",
      "Accuracy,  0.681388856465\n",
      "[[  4191  48967]\n",
      " [ 16255 136195]]\n",
      "Accuracy,  0.682784716548\n",
      "[[  4088  49070]\n",
      " [ 15721 136729]]\n",
      "Accuracy,  0.684880938485\n"
     ]
    }
   ],
   "source": [
    "# pred_probs = (pred_probs-min(pred_probs))/(max(pred_probs)-min(pred_probs))\n",
    "for i in range(0,10,1):\n",
    "    pred = [0 if j>i/10.0 else 1 for j in pred_probs ]\n",
    "    print (confusion_matrix(labels,pred))\n",
    "    print (\"Accuracy, \",  metrics.accuracy_score(labels,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    163331\n",
       "0     42277\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([0 if j > 0.8 else 1 for j in pred_probs ]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    152450\n",
       "0     53158\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(labels).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/pymodules/python2.7/matplotlib/__init__.py:1173: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([array([      0.,       0.,       0.,       0.,       0.,       0.,\n",
       "               0.,       0.,       0.,  205608.]),\n",
       "  array([ 205608.,       0.,       0.,       0.,       0.,       0.,\n",
       "               0.,       0.,       0.,       0.])],\n",
       " array([ 0. ,  0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ]),\n",
       " <a list of 2 Lists of Patches objects>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAFkCAYAAAD7dJuCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd1820d3710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matplotlib.use('Agg')\n",
    "plt.hist(pred_probs,bins=[i/10.0for i in range(0,11,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testdataloader = torch.utils.data.DataLoader(test, batch_size=len(test),\n",
    "                                         shuffle=False, num_workers=int(opt.workers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testdataiter = iter(testdataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testv = Variable(testdataiter.next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([205608, 148])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testv.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "netP = mlp.MLP_P(opt.nSize,  ndf, ngpu)\n",
    "netP.load_state_dict(torch.load('{0}/netD_epoch_{1}.pth'.format(opt.experiment, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_probs = (netP(netG(testv)).data.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.], dtype=float32), array([ 0.], dtype=float32))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(pred_probs),min(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    pred_probs = (pred_probs-min(pred_probs))/(max(pred_probs)-min(pred_probs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     0  53158]\n",
      " [     1 152449]]\n",
      "Accuracy,  0.741454612661\n",
      "[[    10  53148]\n",
      " [    29 152421]]\n",
      "Accuracy,  0.741367067429\n",
      "[[   193  52965]\n",
      " [   598 151852]]\n",
      "Accuracy,  0.739489708572\n",
      "[[  1693  51465]\n",
      " [  4824 147626]]\n",
      "Accuracy,  0.726231469593\n",
      "[[  7591  45567]\n",
      " [ 19759 132691]]\n",
      "Accuracy,  0.682278899654\n",
      "[[20295 32863]\n",
      " [52989 99461]]\n",
      "Accuracy,  0.582448153768\n",
      "[[ 37613  15545]\n",
      " [101433  51017]]\n",
      "Accuracy,  0.431062993658\n",
      "[[ 49490   3668]\n",
      " [138630  13820]]\n",
      "Accuracy,  0.307916034396\n",
      "[[ 52770    388]\n",
      " [150805   1645]]\n",
      "Accuracy,  0.264654099062\n",
      "[[ 53144     14]\n",
      " [152369     81]]\n",
      "Accuracy,  0.258866386522\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10,1):\n",
    "    pred = [1 if j>i/10.0 else 0 for j in pred_probs ]\n",
    "    print (confusion_matrix(labels,pred))\n",
    "    print (\"Accuracy, \",  metrics.accuracy_score(labels,pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 53158      0]\n",
      " [152449      1]]\n",
      "Accuracy,  0.258545387339\n",
      "[[ 33422  19736]\n",
      " [105121  47329]]\n",
      "Accuracy,  0.392742500292\n",
      "[[20374 32784]\n",
      " [66066 86384]]\n",
      "Accuracy,  0.519230769231\n",
      "[[  9657  43501]\n",
      " [ 33499 118951]]\n",
      "Accuracy,  0.62550095327\n",
      "[[  3441  49717]\n",
      " [ 13522 138928]]\n",
      "Accuracy,  0.692429282907\n",
      "[[   945  52213]\n",
      " [  4450 148000]]\n",
      "Accuracy,  0.724412474223\n",
      "[[   201  52957]\n",
      " [  1237 151213]]\n",
      "Accuracy,  0.736420761838\n",
      "[[    42  53116]\n",
      " [   271 152179]]\n",
      "Accuracy,  0.740345706393\n",
      "[[     8  53150]\n",
      " [    49 152401]]\n",
      "Accuracy,  0.741260067702\n",
      "[[     1  53157]\n",
      " [     5 152445]]\n",
      "Accuracy,  0.741440021789\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10,1):\n",
    "    pred = [0 if j>i/10.0 else 1 for j in pred_probs ]\n",
    "    print (confusion_matrix(labels,pred))\n",
    "    print (\"Accuracy, \",  metrics.accuracy_score(labels,pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
